{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "662e62cf-497e-4fc8-bffb-9b2272b75b75",
   "metadata": {
    "id": "662e62cf-497e-4fc8-bffb-9b2272b75b75"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "qNUMRpwq2jiK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNUMRpwq2jiK",
    "outputId": "d1346704-48f3-422e-ddd0-b7dbcfa711c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycuda in /usr/local/lib/python3.11/dist-packages (2024.1.2)\n",
      "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.11/dist-packages (from pycuda) (2025.1.1)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from pycuda) (4.3.6)\n",
      "Requirement already satisfied: mako in /usr/local/lib/python3.11/dist-packages (from pycuda) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from pytools>=2011.2->pycuda) (4.12.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from mako->pycuda) (3.0.2)\n",
      "CPU times: user 20.7 ms, sys: 2.05 ms, total: 22.8 ms\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06bbb65e-eead-424c-ac73-e7666d5ae0be",
   "metadata": {
    "id": "06bbb65e-eead-424c-ac73-e7666d5ae0be"
   },
   "outputs": [],
   "source": [
    "#Import cuda\n",
    "import pycuda\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "993c47d5-91e3-4129-893a-549064bc57c9",
   "metadata": {
    "id": "993c47d5-91e3-4129-893a-549064bc57c9"
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "\n",
    "def compute_pi_cpu(n_points):\n",
    "    #10 000 000 points gave 3.141932\n",
    "    #100 000 000 points gave 3.14141676\n",
    "    #n_total = 1000000\n",
    "\n",
    "    #First, generate random points\n",
    "    rng = np.random.RandomState(42)\n",
    "    x_rand = rng.random(n_points)\n",
    "    y_rand = rng.random(n_points)\n",
    "\n",
    "    #Compute radius from origin\n",
    "    inside = np.sqrt(x_rand**2+y_rand**2) <= 1.0\n",
    "    #Count number of points inside\n",
    "    n_inside = np.sum(inside)\n",
    "\n",
    "    #n_inside = 0\n",
    "    #for i in range(n_points):\n",
    "    #    n_inside += np.sqrt(x_rand[i]**2+y_rand[i]**2) <= 1.0\n",
    "\n",
    "    #We can estimate pi by the following formula:\n",
    "    #pi = 4 * n_inside / n_total\n",
    "    pi = 4*n_inside/n_points\n",
    "\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5bbe45c6-eb3a-4179-a1b0-8c5a6328b35e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bbe45c6-eb3a-4179-a1b0-8c5a6328b35e",
    "outputId": "25dd9360-d0ea-417a-f2fb-1f5e0cee5a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1418\n",
      "Time taken: 0.141325 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "print(compute_pi_cpu(5120000))\n",
    "toc = time.time()\n",
    "\n",
    "#for loop: 1.84 seconds for 512 000 elements\n",
    "#vectorized: 0.018 seconds for 512 000 elements => 100 times faster!!!\n",
    "\n",
    "print(\"Time taken: {:f} seconds\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75fce2ec-ed1a-4650-8ef4-473c38d9933f",
   "metadata": {
    "id": "75fce2ec-ed1a-4650-8ef4-473c38d9933f"
   },
   "outputs": [],
   "source": [
    "pi_kernel_src = \"\"\"\n",
    "//Based on Stroustrup, adapted for CUDA\n",
    "//pseudorandom numbers\n",
    "__device__ float generateRandomNumber(long& last_draw) {\n",
    "    last_draw = last_draw*1103515245 + 12345;\n",
    "    long abs = last_draw & 0x7fffffff;\n",
    "    return abs / 2147483648.0;\n",
    "}\n",
    "\n",
    "\n",
    "__global__ void computePi(unsigned int* inside, unsigned int num_iterations, unsigned int seed) {\n",
    "    __shared__ unsigned int inside_shared[512];\n",
    "\n",
    "    unsigned int tid = threadIdx.x;\n",
    "    unsigned int bid = blockIdx.x;\n",
    "\n",
    "    //1 generate random numbers\n",
    "    unsigned int num_inside = 0;\n",
    "    for (int i=0; i<num_iterations; ++i) {\n",
    "        long rand_seed = seed + blockIdx.x*blockDim.x + threadIdx.x;\n",
    "        float x = generateRandomNumber(rand_seed);\n",
    "        float y = generateRandomNumber(rand_seed);\n",
    "\n",
    "        //2 compute radius from origin\n",
    "        float r = sqrt(x*x+y*y);\n",
    "\n",
    "        //3 check if inside circle and write to memory\n",
    "        if (r <= 1) {\n",
    "            num_inside += 1;\n",
    "        }\n",
    "    }\n",
    "    inside_shared[tid] = num_inside;\n",
    "\n",
    "    /////////////////////////\n",
    "    //Shared memory reduction\n",
    "    /////////////////////////\n",
    "\n",
    "    // Synchronze so that all thread see the same shared memory\n",
    "    __syncthreads();\n",
    "\n",
    "    // Find the sum in shared memory\n",
    "    //Reduce from 512 to 256 elements\n",
    "    if (threadIdx.x < 256) {\n",
    "        inside_shared[threadIdx.x] = inside_shared[threadIdx.x] + inside_shared[threadIdx.x + 256];\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    //Reduce from 256 to 128 elements\n",
    "    if (threadIdx.x < 128) {\n",
    "        inside_shared[threadIdx.x] = inside_shared[threadIdx.x] + inside_shared[threadIdx.x + 128];\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    //Reduce from 128 to 64 elements\n",
    "    if (threadIdx.x < 64) {\n",
    "        inside_shared[threadIdx.x] = inside_shared[threadIdx.x] + inside_shared[threadIdx.x + 64];\n",
    "    }\n",
    "    __syncthreads();\n",
    "\n",
    "    //Reduce from 32 to 16 elements\n",
    "    //Since we here have only one active warp (threadIdx.x > 32)\n",
    "    //we do not need to call syncthreads anymore\n",
    "    volatile unsigned int* p = &inside_shared[0]; //To help the compiler not cache this variable...\n",
    "    if (threadIdx.x < 32) {\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 32];\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 16];\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 8];\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 4];\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 2];\n",
    "        p[threadIdx.x] = p[threadIdx.x] + p[threadIdx.x + 1];\n",
    "    }\n",
    "\n",
    "    // Finally write out to output\n",
    "    // NOTE: We have 512 threads, but only thread 0 writes to memory\n",
    "    if (threadIdx.x == 0) {\n",
    "        inside[bid] = p[0];\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "mod = SourceModule(pi_kernel_src)\n",
    "compute_pi_gpu_kernel = mod.get_function(\"computePi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "936395a1-3289-4b9b-8610-6db971f196d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "936395a1-3289-4b9b-8610-6db971f196d6",
    "outputId": "e7d0a0da-efe5-423c-d2a6-bac639f6352b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.140625\n",
      "Time taken: 0.002046 seconds\n"
     ]
    }
   ],
   "source": [
    "def compute_pi_gpu(n_points, iterations_per_thread=1000, threads_per_block=512):\n",
    "    #10 000 000 points gave 3.141932\n",
    "    #100 000 000 points gave 3.14141676\n",
    "    #n_total = 1000000\n",
    "\n",
    "    assert(n_points % (threads_per_block*iterations_per_thread) == 0)\n",
    "\n",
    "    #Allocate output data on the GPU\n",
    "    #Bytes per unsigned int:\n",
    "    bytes_per_uint = 4\n",
    "    inside_gpu = cuda.mem_alloc(bytes_per_uint*(n_points//threads_per_block)//iterations_per_thread)\n",
    "\n",
    "    #Execute the pi-kernel\n",
    "    num_blocks = (n_points // threads_per_block)//iterations_per_thread\n",
    "    block=(threads_per_block,1,1)\n",
    "    grid=(num_blocks,1,1)\n",
    "    compute_pi_gpu_kernel(inside_gpu, np.uint32(iterations_per_thread), np.uint32(time.time()), block=(threads_per_block,1,1), grid=(num_blocks,1,1))\n",
    "    \n",
    "    #Allocate memory to download to on the CPU\n",
    "    inside_cpu = np.empty((n_points//threads_per_block)//iterations_per_thread, dtype=np.uint32)\n",
    "\n",
    "    #Download from the GPU to the CPU\n",
    "    cuda.memcpy_dtoh(inside_cpu, inside_gpu)\n",
    "\n",
    "    #Count number of points inside\n",
    "    # Version 6: move this reduction to the GPU, and only transfer a single number to the CPU.\n",
    "    n_inside = np.sum(inside_cpu)\n",
    "\n",
    "    #We can estimate pi by the following formula:\n",
    "    pi = 4*n_inside/n_points\n",
    "\n",
    "    return pi\n",
    "\n",
    "tic = time.time()\n",
    "print(compute_pi_gpu(5120000, 10000, 512))\n",
    "toc = time.time()\n",
    "\n",
    "print(\"Time taken: {:f} seconds\".format(toc-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3ed16a63-e7fd-48fe-a1fe-3d001d835c7c",
   "metadata": {
    "id": "3ed16a63-e7fd-48fe-a1fe-3d001d835c7c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
